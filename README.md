# CoCoSeg: åŸºäºVMambaçš„CT-PETåŒæ¨¡æ€åŒ»ç–—å›¾åƒåˆ†å‰²æ¨¡å‹

## ğŸ“‹ é¡¹ç›®ç®€ä»‹

CoCoSegæ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºCT-PETåŒæ¨¡æ€åŒ»ç–—å›¾åƒåˆ†å‰²çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚æœ¬é¡¹ç›®åŸºäº**VMamba (Vision Mamba)**æ¶æ„ï¼Œé‡‡ç”¨åŒç‹¬ç«‹ç¼–ç å™¨å’Œå¤šå±‚çº§ç‰¹å¾èåˆç­–ç•¥ï¼Œå®ç°äº†é«˜è´¨é‡çš„å¤šæ¨¡æ€åŒ»ç–—å›¾åƒåˆ†å‰²ã€‚æ¨¡å‹æ”¯æŒ512Ã—512åƒç´ çš„CT-PETå›¾åƒå¯¹ï¼Œä¸“é—¨ç”¨äºè‚¿ç˜¤ç­‰ç—…ç¶çš„ç²¾ç¡®åˆ†å‰²ä»»åŠ¡ã€‚

### æ ¸å¿ƒç‰¹ç‚¹

- âœ… **VMambaæ¶æ„**: åŸºäºçŠ¶æ€ç©ºé—´æ¨¡å‹(SSM)çš„é«˜æ•ˆè§†è§‰ç¼–ç å™¨ï¼Œçº¿æ€§å¤æ‚åº¦
- âœ… **åŒç‹¬ç«‹ç¼–ç å™¨**: CTå’ŒPETå„ä½¿ç”¨ç‹¬ç«‹çš„VMambaç¼–ç å™¨ï¼Œä¿æŒæ¨¡æ€ç‰¹å¼‚æ€§
- âœ… **å¤šå±‚çº§èåˆ**: CRM (Channel Rectify Module) + DCIM (Dual Cross-Modal Interaction) + è‡ªé€‚åº”èåˆ
- âœ… **MambaDecoder**: åŸºäºVMambaçš„ä¸Šé‡‡æ ·è§£ç å™¨ï¼Œä¿æŒæ¶æ„ä¸€è‡´æ€§
- âœ… **å…ˆè¿›è®­ç»ƒç­–ç•¥**: EMAã€æ··åˆç²¾åº¦è®­ç»ƒã€é˜ˆå€¼æ‰«æã€æ—©åœæœºåˆ¶
- âœ… **å¤šç§æŸå¤±å‡½æ•°**: æ”¯æŒTversky+BCEã€Dice+CEç­‰å¤šç§ç»„åˆ

---

## ğŸ—ï¸ æ¨¡å‹æ¶æ„è¯¦è§£

> ğŸ“ **æ¶æ„å›¾ç»˜åˆ¶æŒ‡å—**: è¯¦ç»†çš„æ¶æ„è¯´æ˜å’Œç»˜å›¾æŒ‡å—è¯·å‚è€ƒ [ARCHITECTURE_DIAGRAM.md](./ARCHITECTURE_DIAGRAM.md)ï¼ŒåŒ…å«ä¸CIPAçš„å¯¹æ¯”å’Œç»˜å›¾å»ºè®®ã€‚

### æ•´ä½“æ¶æ„æ¦‚è§ˆ

CoCoSegé‡‡ç”¨**ç¼–ç å™¨-è§£ç å™¨(Encoder-Decoder)**æ¶æ„ï¼Œä¸“é—¨è®¾è®¡ç”¨äºCT-PETåŒæ¨¡æ€åˆ†å‰²ï¼š

```
è¾“å…¥å±‚:
â”œâ”€â”€ CTå›¾åƒ [B, 1, 512, 512] â†’ å¤åˆ¶ä¸º3é€šé“ [B, 3, 512, 512]
â””â”€â”€ PETå›¾åƒ [B, 1, 512, 512] â†’ å¤åˆ¶ä¸º3é€šé“ [B, 3, 512, 512]

ç¼–ç å™¨å±‚ (åŒç‹¬ç«‹VMamba):
â”œâ”€â”€ CT_VMamba_Encoder â†’ 4å±‚ç‰¹å¾: [96, 192, 384, 768] channels
â””â”€â”€ PET_VMamba_Encoder â†’ 4å±‚ç‰¹å¾: [96, 192, 384, 768] channels

å¤šå±‚çº§èåˆ (4ä¸ªå±‚çº§):
â”œâ”€â”€ Level 1 (96ch):  CRM â†’ DCIM â†’ Adaptive Fusion
â”œâ”€â”€ Level 2 (192ch): CRM â†’ DCIM â†’ Adaptive Fusion  
â”œâ”€â”€ Level 3 (384ch): CRM â†’ DCIM â†’ Adaptive Fusion
â””â”€â”€ Level 4 (768ch): CRM â†’ DCIM â†’ Adaptive Fusion

è§£ç å™¨å±‚ (MambaDecoder):
â”œâ”€â”€ ä¸Šé‡‡æ · + è·³è·ƒè¿æ¥ (4å±‚)
â””â”€â”€ è¾“å‡ºå±‚ â†’ [B, 1, 512, 512]
```

### 1. VMambaç¼–ç å™¨æ¶æ„

#### 1.1 VMamba Backbone

æ¨¡å‹æä¾›ä¸‰ç§VMamba backboneï¼ˆä¸`models/vmamba/dual_vmamba.py`å’Œ`models/vmamba/builder.py`ä¸€è‡´ï¼‰ï¼š

```python
# VMamba backbone é…ç½®ï¼ˆå½“å‰ä»£ç å®é™…å–å€¼ï¼‰
backbone = 'sigma_tiny'     # å¯é€‰: sigma_tiny / sigma_small / sigma_base
depths = [2, 2, 9, 2]       # sigma_tiny
dims = 96
channels = [96, 192, 384, 768]
pretrained = './pretrained/vmamba/vssmtiny_dp01_ckpt_epoch_292.pth'
patch_size = 4
image_size = [512, 512]

# sigma_small: depths=[2, 2, 27, 2], dims=96
# sigma_base:  depths=[2, 2, 27, 2], dims=128
```

**å››ä¸ªStageçš„è¯¦ç»†ç»“æ„**ï¼ˆä»¥ `sigma_tiny` ä¸ºä¾‹ï¼‰ï¼š

| Stage | è¾“å…¥å°ºå¯¸ | è¾“å‡ºé€šé“ | Blockæ•° | åˆ†è¾¨ç‡å˜åŒ– |
|-------|---------|---------|---------|-----------|
| Stage 1 | 512Ã—512 | 96 | 2 | 512Ã—512 â†’ 128Ã—128 |
| Stage 2 | 128Ã—128 | 192 | 2 | 128Ã—128 â†’ 64Ã—64 |
| Stage 3 | 64Ã—64 | 384 | 9 | 64Ã—64 â†’ 32Ã—32 |
| Stage 4 | 32Ã—32 | 768 | 2 | 32Ã—32 â†’ 16Ã—16 |

#### 1.2 SS2D (Selective Scan 2D) æ ¸å¿ƒæ¨¡å—

VMambaçš„æ ¸å¿ƒæ˜¯**SS2D (Selective Scan 2D)**æ¨¡å—ï¼ŒåŸºäºçŠ¶æ€ç©ºé—´æ¨¡å‹(SSM)ï¼š

```python
class SS2D(nn.Module):
    """äºŒç»´é€‰æ‹©æ€§æ‰«ææ¨¡å— - VMambaçš„æ ¸å¿ƒ"""
    def __init__(self, d_model=96, d_state=16, ssm_ratio=2, ...):
        # è¾“å…¥æŠ•å½±: d_model â†’ d_inner * 2
        self.in_proj = nn.Linear(d_model, d_inner * 2)
        
        # æ·±åº¦å¯åˆ†ç¦»å·ç§¯ (å¯é€‰)
        self.conv2d = nn.Conv2d(d_inner, d_inner, groups=d_inner, ...)
        
        # SSMå‚æ•°
        self.x_proj_weight  # çŠ¶æ€æŠ•å½±æƒé‡
        self.dt_projs_weight  # æ—¶é—´æ­¥æŠ•å½±æƒé‡
        self.A_logs, self.Ds  # çŠ¶æ€è½¬ç§»çŸ©é˜µ
        
    def forward_core(self, x):
        # 1. å››æ–¹å‘æ‰«æ (CrossScan)
        xs = CrossScan.apply(x)  # [B, 4, D, H*W]
        # å››ä¸ªæ–¹å‘: HW, WH, ç¿»è½¬HW, ç¿»è½¬WH
        
        # 2. é€‰æ‹©æ€§æ‰«æ (Selective Scan)
        ys = SelectiveScan.apply(xs, dts, As, Bs, Cs, Ds, ...)
        
        # 3. åˆå¹¶å››æ–¹å‘ç»“æœ (CrossMerge)
        y = CrossMerge.apply(ys)  # [B, D, H*W]
        return y
```

**SS2Dçš„å·¥ä½œåŸç†**ï¼š

1. **CrossScan (äº¤å‰æ‰«æ)**: å°†2Dç‰¹å¾å›¾è½¬æ¢ä¸º4ä¸ªæ–¹å‘çš„1Dåºåˆ—
   - æ–¹å‘1: è¡Œä¼˜å…ˆæ‰«æ (HÃ—W)
   - æ–¹å‘2: åˆ—ä¼˜å…ˆæ‰«æ (WÃ—H)
   - æ–¹å‘3: ç¿»è½¬è¡Œä¼˜å…ˆæ‰«æ
   - æ–¹å‘4: ç¿»è½¬åˆ—ä¼˜å…ˆæ‰«æ

2. **Selective Scan (é€‰æ‹©æ€§æ‰«æ)**: å¯¹æ¯ä¸ªæ–¹å‘çš„åºåˆ—åº”ç”¨çŠ¶æ€ç©ºé—´æ¨¡å‹
   - çŠ¶æ€æ–¹ç¨‹: `h(t) = A * h(t-1) + B * x(t)`
   - è¾“å‡ºæ–¹ç¨‹: `y(t) = C * h(t) + D * x(t)`
   - çº¿æ€§å¤æ‚åº¦: O(N) vs Transformerçš„O(NÂ²)

3. **CrossMerge (äº¤å‰åˆå¹¶)**: å°†4ä¸ªæ–¹å‘çš„ç»“æœåˆå¹¶å›2Dç‰¹å¾å›¾

**ä¼˜åŠ¿**ï¼š
- **çº¿æ€§å¤æ‚åº¦**: O(N) vs Transformerçš„O(NÂ²)ï¼Œé€‚åˆé«˜åˆ†è¾¨ç‡å›¾åƒ
- **é•¿è·ç¦»ä¾èµ–**: SSMå¤©ç„¶é€‚åˆå»ºæ¨¡é•¿åºåˆ—ä¾èµ–
- **é«˜æ•ˆè®¡ç®—**: ç›¸æ¯”Self-Attentionï¼Œè®¡ç®—å’Œå†…å­˜æ›´é«˜æ•ˆ

#### 1.3 åŒç‹¬ç«‹ç¼–ç å™¨è®¾è®¡

CTå’ŒPETä½¿ç”¨**å®Œå…¨ç‹¬ç«‹çš„VMambaç¼–ç å™¨**ï¼ˆä¸å…±äº«æƒé‡ï¼‰ï¼š

```python
class RGBXTransformer(nn.Module):
    def __init__(self, ...):
        # CTç¼–ç å™¨ (ç‹¬ç«‹æƒé‡)
        self.vssm_rgb = Backbone_VSSM(
            in_chans=3,  # å•é€šé“å¤åˆ¶ä¸º3é€šé“ä»¥åˆ©ç”¨é¢„è®­ç»ƒæƒé‡
            depths=[2, 2, 9, 2],
            dims=96,
            pretrained='./pretrained/vmamba/vssmtiny_dp01_ckpt_epoch_292.pth'
        )
        
        # PETç¼–ç å™¨ (ç‹¬ç«‹æƒé‡)
        self.vssm_x = Backbone_VSSM(
            in_chans=3,  # å•é€šé“å¤åˆ¶ä¸º3é€šé“
            depths=[2, 2, 9, 2],
            dims=96,
            pretrained='./pretrained/vmamba/vssmtiny_dp01_ckpt_epoch_292.pth'
        )
```

**è®¾è®¡ç†å¿µ**ï¼š
- **æ¨¡æ€ç‰¹å¼‚æ€§**: CTå’ŒPETå…·æœ‰ä¸åŒçš„æˆåƒåŸç†å’Œç‰¹å¾åˆ†å¸ƒï¼Œç‹¬ç«‹ç¼–ç å™¨å¯ä»¥å­¦ä¹ å„è‡ªæ¨¡æ€çš„ç‹¬ç‰¹ç‰¹å¾
- **é¢„è®­ç»ƒæƒé‡**: å•é€šé“å›¾åƒå¤åˆ¶ä¸º3é€šé“ï¼Œå……åˆ†åˆ©ç”¨ImageNeté¢„è®­ç»ƒçš„VMambaæƒé‡
- **ç‰¹å¾äº’è¡¥**: ä¸¤ä¸ªç¼–ç å™¨æå–çš„ç‰¹å¾åœ¨åç»­èåˆé˜¶æ®µäº’è¡¥ï¼Œæå‡åˆ†å‰²æ€§èƒ½

### 2. å¤šå±‚çº§ç‰¹å¾èåˆæœºåˆ¶

æ¨¡å‹åœ¨4ä¸ªå±‚çº§è¿›è¡ŒCT-PETç‰¹å¾èåˆï¼Œæ¯ä¸ªå±‚çº§åŒ…å«ä¸‰ä¸ªå…³é”®æ¨¡å—ï¼š

#### 2.1 CRM (Channel Rectify Module) - é€šé“æ ¡æ­£æ¨¡å—

CRMç”¨äºè·¨æ¨¡æ€ç‰¹å¾å¯¹é½ï¼Œå­¦ä¹ æ¯ä¸ªé€šé“çš„é‡è¦æ€§æƒé‡ï¼š

```python
class ChannelRectifyModule(nn.Module):
    """é€šé“æ ¡æ­£æ¨¡å— - å­¦ä¹ CTå’ŒPETç‰¹å¾çš„é€šé“æƒé‡"""
    def __init__(self, dim, HW, reduction=16):
        # ChannelWeights: ä½¿ç”¨SS1Då­¦ä¹ é€šé“æƒé‡
        self.channel_weights = ChannelWeights(dim=HW, channel_dim=dim)
    
    def forward(self, x1, x2):
        # x1: CTç‰¹å¾ [B, C, H, W]
        # x2: PETç‰¹å¾ [B, C, H, W]
        
        # å­¦ä¹ é€šé“æƒé‡ [2, B, C, 1, 1]
        channel_weights = self.channel_weights(x1, x2)
        
        # é€šé“åŠ æƒå¢å¼º
        out_x1 = x1 + channel_weights[0] * x1  # CTç‰¹å¾å¢å¼º
        out_x2 = x2 + channel_weights[1] * x2  # PETç‰¹å¾å¢å¼º
        
        return out_x1, out_x2
```

**ChannelWeightså†…éƒ¨ç»“æ„**ï¼š

```python
class ChannelWeights(nn.Module):
    def __init__(self, dim, channel_dim, reduction=4):
        self.mlp = nn.Sequential(
            nn.LayerNorm(dim),           # H*Wç»´åº¦å½’ä¸€åŒ–
            nn.Linear(dim, 96),          # é™ç»´
            nn.GELU(),
            SS1D(d_model=96, ...),       # ä½¿ç”¨SS1Då¤„ç†åºåˆ—
            nn.LayerNorm(96),
            nn.Linear(96, 1),            # è¾“å‡ºæƒé‡
            nn.Sigmoid()                 # å½’ä¸€åŒ–åˆ°[0,1]
        )
    
    def forward(self, x1, x2):
        B, C, H, W = x1.shape
        # æ‹¼æ¥CTå’ŒPETç‰¹å¾
        x = torch.cat([x1, x2], dim=1).view(B, 2*C, H*W)  # [B, 2C, HW]
        # å­¦ä¹ é€šé“æƒé‡
        channel_weights = self.mlp(x)  # [B, 2C, 1]
        return channel_weights.reshape(B, 2, C, 1, 1).permute(1, 0, 2, 3, 4)
```

**åŠŸèƒ½**ï¼š
- **é€šé“å¯¹é½**: è‡ªåŠ¨å­¦ä¹ CTå’ŒPETç‰¹å¾ä¸­å“ªäº›é€šé“æ›´é‡è¦
- **è·¨æ¨¡æ€äº¤äº’**: é€šè¿‡æ‹¼æ¥å’ŒSS1Då¤„ç†ï¼Œå®ç°è·¨æ¨¡æ€çš„é€šé“æƒé‡å­¦ä¹ 
- **è‡ªé€‚åº”å¢å¼º**: å¯¹é‡è¦é€šé“è¿›è¡ŒåŠ æƒå¢å¼ºï¼ŒæŠ‘åˆ¶å™ªå£°é€šé“

#### 2.2 DCIM (Dual Cross-Modal Interaction Module) - åŒäº¤å‰æ¨¡æ€äº¤äº’æ¨¡å—

DCIMé€šè¿‡åŒºåŸŸMambaå®ç°è·¨æ¨¡æ€çš„ç»†ç²’åº¦äº¤äº’ï¼š

```python
# DCIMåŒ…å«ä¸¤ä¸ªç»„ä»¶:
# 1. Region Patch (åŒºåŸŸåˆ†å—)
cross_rgb, cross_x, (H_out, W_out), (H_in, W_in) = self.region_patch[i](
    cross_rgb, cross_x
)

# 2. Channel Attention Mamba (é€šé“æ³¨æ„åŠ›Mamba)
attn_output = self.channel_attn_mamba[i](
    cross_rgb.contiguous(), 
    cross_x.contiguous(),
    H_out, W_out, H_in, W_in
).permute(0, 3, 1, 2).contiguous()
```

**Region Patchæ¨¡å—**ï¼š
- å°†ç‰¹å¾å›¾åˆ’åˆ†ä¸ºå¤šä¸ªå°åŒºåŸŸ(å¦‚4Ã—4 patches)
- æ¯ä¸ªåŒºåŸŸç‹¬ç«‹å¤„ç†ï¼Œä¿æŒå±€éƒ¨ç»†èŠ‚
- è¾“å‡ºåŒºåŸŸç‰¹å¾å’Œç©ºé—´ç»´åº¦ä¿¡æ¯

**Channel Attention Mamba**ï¼š
- ä½¿ç”¨åŒºåŸŸMambaå¤„ç†è·¨æ¨¡æ€äº¤äº’
- å­¦ä¹ CTå’ŒPETåŒºåŸŸä¹‹é—´çš„æ³¨æ„åŠ›æƒé‡
- è¾“å‡ºè·¨æ¨¡æ€å¢å¼ºçš„ç‰¹å¾

#### 2.3 Adaptive Fusion Module - è‡ªé€‚åº”èåˆæ¨¡å—

è‡ªé€‚åº”èåˆæ¨¡å—å­¦ä¹ CTå’ŒPETçš„æœ€ä¼˜èåˆæƒé‡ï¼š

```python
class AdaptiveFusionModule(nn.Module):
    """è‡ªé€‚åº”æ¨¡æ€èåˆæ¨¡å— - å­¦ä¹ CTå’ŒPETçš„æœ€ä¼˜èåˆæƒé‡"""
    def __init__(self, dim):
        self.weight_net = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),           # å…¨å±€å¹³å‡æ± åŒ–
            nn.Conv2d(dim * 2, max(dim // 4, 16), 1),  # é™ç»´
            nn.ReLU(),
            nn.Conv2d(max(dim // 4, 16), 2, 1),  # è¾“å‡º2ä¸ªæƒé‡
            nn.Softmax(dim=1)                   # å½’ä¸€åŒ–
        )
    
    def forward(self, feat_rgb, feat_x):
        # æ‹¼æ¥ç‰¹å¾
        concat_feat = torch.cat([feat_rgb, feat_x], dim=1)  # [B, 2C, H, W]
        
        # å­¦ä¹ èåˆæƒé‡
        weights = self.weight_net(concat_feat)  # [B, 2, 1, 1]
        w_rgb, w_x = weights[:, 0:1], weights[:, 1:2]
        
        # è‡ªé€‚åº”åŠ æƒèåˆ
        fused = w_rgb * feat_rgb + w_x * feat_x
        return fused
```

**èåˆç­–ç•¥**ï¼š
```python
# å®Œæ•´èåˆæµç¨‹ (æ¯ä¸ªå±‚çº§)
for i in range(4):  # 4ä¸ªå±‚çº§
    # 1. CRM: é€šé“æ ¡æ­£
    cross_rgb, cross_x = self.cross_mamba[i](out_rgb, out_x)
    
    # 2. DCIM: åŒºåŸŸäº¤äº’
    cross_rgb, cross_x, (H_out, W_out), (H_in, W_in) = \
        self.region_patch[i](cross_rgb, cross_x)
    attn_output = self.channel_attn_mamba[i](
        cross_rgb, cross_x, H_out, W_out, H_in, W_in
    )
    
    # 3. Adaptive Fusion: è‡ªé€‚åº”èåˆ
    adaptive_fused = self.adaptive_fusion[i](out_rgb, out_x)
    
    # 4. æœ€ç»ˆèåˆ: æ³¨æ„åŠ›è¾“å‡º + è‡ªé€‚åº”èåˆ
    x_fuse = adaptive_fused + attn_output
    outs_fused.append(x_fuse)
```

### 3. MambaDecoder è§£ç å™¨æ¶æ„

MambaDecoderé‡‡ç”¨ä¸ç¼–ç å™¨ä¸€è‡´çš„VMambaæ¶æ„ï¼Œé€šè¿‡ä¸Šé‡‡æ ·é€æ­¥æ¢å¤åˆ†è¾¨ç‡ï¼š

```python
class MambaDecoder(nn.Module):
    def __init__(self, 
                 img_size=[512, 512],
                 in_channels=[96, 192, 384, 768],
                 num_classes=1,
                 embed_dim=96,
                 depths=[4, 4, 4, 4]):
        # 4ä¸ªä¸Šé‡‡æ ·å±‚
        self.layers_up = nn.ModuleList()
        for i_layer in range(4):
            if i_layer == 0:
                # ç¬¬ä¸€å±‚: PatchExpand (768 â†’ 384)
                layer_up = PatchExpand(...)
            else:
                # å…¶ä»–å±‚: Mamba_up (åŒ…å«CVSSDecoderBlock)
                layer_up = Mamba_up(
                    dim=embed_dim * 2 ** (3 - i_layer),
                    depth=depths[3 - i_layer],
                    upsample=PatchExpand if (i_layer < 3) else None
                )
            self.layers_up.append(layer_up)
        
        # æœ€ç»ˆä¸Šé‡‡æ · (4å€)
        self.up = FinalUpsample_X4(...)
        self.output = nn.Conv2d(embed_dim, num_classes, 1)
```

**è§£ç å™¨æµç¨‹**ï¼š

| å±‚çº§ | è¾“å…¥ | æ“ä½œ | è¾“å‡º | åˆ†è¾¨ç‡ |
|------|------|------|------|--------|
| Layer 0 | 768ch, 16Ã—16 | PatchExpand | 384ch, 32Ã—32 | 2Ã—ä¸Šé‡‡æ · |
| Layer 1 | 384ch, 32Ã—32 | Mamba_up + Skip | 192ch, 64Ã—64 | 2Ã—ä¸Šé‡‡æ · |
| Layer 2 | 192ch, 64Ã—64 | Mamba_up + Skip | 96ch, 128Ã—128 | 2Ã—ä¸Šé‡‡æ · |
| Layer 3 | 96ch, 128Ã—128 | Mamba_up + Skip | 96ch, 128Ã—128 | ä¿æŒ |
| Final | 96ch, 128Ã—128 | FinalUpsample_X4 | 1ch, 512Ã—512 | 4Ã—ä¸Šé‡‡æ · |

**CVSSDecoderBlock** (è§£ç å™¨ä¸­çš„æ ¸å¿ƒblock)ï¼š

```python
class CVSSDecoderBlock(nn.Module):
    """VMambaè§£ç å™¨Block"""
    def __init__(self, hidden_dim, ...):
        self.norm1 = norm_layer(hidden_dim)
        self.ssm = SS2D(d_model=hidden_dim, ...)  # SS2Dæ¨¡å—
        self.norm2 = norm_layer(hidden_dim)
        self.mlp = Mlp(hidden_dim, ...)  # MLP
        
    def forward(self, x):
        # æ®‹å·®è¿æ¥ + SS2D
        x = x + self.ssm(self.norm1(x))
        # æ®‹å·®è¿æ¥ + MLP
        x = x + self.mlp(self.norm2(x))
        return x
```

**è·³è·ƒè¿æ¥**ï¼š
- è§£ç å™¨æ¯å±‚ä¸å¯¹åº”å±‚çº§çš„èåˆç‰¹å¾è¿›è¡Œè·³è·ƒè¿æ¥
- ä¿æŒç»†èŠ‚ä¿¡æ¯ï¼Œæå‡åˆ†å‰²ç²¾åº¦

### 4. å®Œæ•´æ•°æ®æµ

```
è¾“å…¥é˜¶æ®µ:
â”œâ”€â”€ CT [B,1,512,512] â†’ repeat(1,3,1,1) â†’ [B,3,512,512]
â””â”€â”€ PET [B,1,512,512] â†’ repeat(1,3,1,1) â†’ [B,3,512,512]

ç¼–ç é˜¶æ®µ (åŒç‹¬ç«‹VMamba):
â”œâ”€â”€ CT_VMamba:
â”‚   â”œâ”€â”€ Stage1: [B,3,512,512] â†’ [B,96,128,128]   (patch_size=4)
â”‚   â”œâ”€â”€ Stage2: [B,96,128,128] â†’ [B,192,64,64]   (ä¸‹é‡‡æ ·2Ã—)
â”‚   â”œâ”€â”€ Stage3: [B,192,64,64] â†’ [B,384,32,32]    (ä¸‹é‡‡æ ·2Ã—)
â”‚   â””â”€â”€ Stage4: [B,384,32,32] â†’ [B,768,16,16]    (ä¸‹é‡‡æ ·2Ã—)
â”‚
â””â”€â”€ PET_VMamba:
    â”œâ”€â”€ Stage1: [B,3,512,512] â†’ [B,96,128,128]
    â”œâ”€â”€ Stage2: [B,96,128,128] â†’ [B,192,64,64]
    â”œâ”€â”€ Stage3: [B,192,64,64] â†’ [B,384,32,32]
    â””â”€â”€ Stage4: [B,384,32,32] â†’ [B,768,16,16]

èåˆé˜¶æ®µ (4ä¸ªå±‚çº§):
â”œâ”€â”€ Level 4 (768ch, 16Ã—16):
â”‚   â”œâ”€â”€ CRM: CT(768) + PET(768) â†’ cross_CT, cross_PET
â”‚   â”œâ”€â”€ DCIM: Region Patch + Channel Attn Mamba â†’ attn_output
â”‚   â””â”€â”€ Adaptive Fusion: CT + PET â†’ fused(768)
â”‚
â”œâ”€â”€ Level 3 (384ch, 32Ã—32):
â”‚   â”œâ”€â”€ CRM â†’ cross_CT, cross_PET
â”‚   â”œâ”€â”€ DCIM â†’ attn_output
â”‚   â””â”€â”€ Adaptive Fusion â†’ fused(384)
â”‚
â”œâ”€â”€ Level 2 (192ch, 64Ã—64):
â”‚   â”œâ”€â”€ CRM â†’ cross_CT, cross_PET
â”‚   â”œâ”€â”€ DCIM â†’ attn_output
â”‚   â””â”€â”€ Adaptive Fusion â†’ fused(192)
â”‚
â””â”€â”€ Level 1 (96ch, 128Ã—128):
    â”œâ”€â”€ CRM â†’ cross_CT, cross_PET
    â”œâ”€â”€ DCIM â†’ attn_output
    â””â”€â”€ Adaptive Fusion â†’ fused(96)

è§£ç é˜¶æ®µ (MambaDecoder):
â”œâ”€â”€ Layer 0: fused(768,16Ã—16) â†’ PatchExpand â†’ (384,32Ã—32)
â”œâ”€â”€ Layer 1: (384,32Ã—32) + Skip(384) â†’ Mamba_up â†’ (192,64Ã—64)
â”œâ”€â”€ Layer 2: (192,64Ã—64) + Skip(192) â†’ Mamba_up â†’ (96,128Ã—128)
â”œâ”€â”€ Layer 3: (96,128Ã—128) + Skip(96) â†’ Mamba_up â†’ (96,128Ã—128)
â””â”€â”€ Final: (96,128Ã—128) â†’ FinalUpsample_X4 â†’ (1,512Ã—512)

è¾“å‡º:
â””â”€â”€ [B, 1, 512, 512] (åˆ†å‰²mask)
```

---

## ğŸ“Š è®­ç»ƒç»“æœ

åŸºäºè®­ç»ƒæ—¥å¿— `logs/20251218_230355/` çš„ç»“æœï¼š

### è®­ç»ƒé…ç½®

```json
{
    "epoch": 50,
    "lr": 6e-05,
    "bs": 4,
    "loss_type": "tversky_bce",
    "tversky_weight": 0.7,
    "bce_weight": 0.3,
    "tversky_alpha": 0.7,  // æ›´å…³æ³¨å‡é˜´æ€§(æ¼æ£€)
    "tversky_beta": 0.3,   // å‡é˜³æ€§æƒé‡
    "model_type": "vmamba",
    "backbone": "sigma_tiny",
    "patience": 25,
    "warmup_epochs": 5,
    "weight_decay": 0.01,
    "amp": true  // æ··åˆç²¾åº¦è®­ç»ƒ
}
```

### æ€§èƒ½æŒ‡æ ‡

**æœ€ä½³éªŒè¯ç»“æœ** (Epoch 50):
- **æœ€ä½³Dice**: 0.7755 (é˜ˆå€¼æ‰«æ)
- **æœ€ä½³é˜ˆå€¼**: 0.35
- **IoU**: ~0.63
- **F1**: ~0.77
- **HD95**: ~20.5mm

**è®­ç»ƒæ›²çº¿è¶‹åŠ¿**:
- è®­ç»ƒLoss: 0.739 â†’ 0.085 (æŒç»­ä¸‹é™)
- è®­ç»ƒDice: 0.031 â†’ 0.861 (æŒç»­ä¸Šå‡)
- éªŒè¯Dice: 0.203 â†’ 0.775 (ç¨³å®šæå‡)
- éªŒè¯HD95: ~20-21mm (ç¨³å®š)

### æ¨¡å‹å‚æ•°é‡

- **æ€»å‚æ•°é‡**: ~33M (VMamba Tiny)
- **å¯è®­ç»ƒå‚æ•°**: ~33M
- **æ¨¡å‹å¤§å°**: ~780MB (best_model.pth)

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒé…ç½®

#### 1. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

```bash
conda create -n cocoseg python=3.10
conda activate cocoseg
```

#### 2. å®‰è£…PyTorch

```bash
# CUDA 12.1/12.4 (æ¨è)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# CUDA 11.8
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

#### 3. å®‰è£…ä¾èµ–

```bash
cd CoCoSeg
pip install -r requirements.txt
```

#### 4. ç¼–è¯‘Selective Scan CUDAæ‰©å±•

```bash
cd models/vmamba/selective_scan
python setup.py build_ext --inplace
cd ../../..
```

### æ•°æ®é›†å‡†å¤‡

æ”¯æŒPCLT20Kæ ¼å¼æ•°æ®é›†ï¼Œç›®å½•ç»“æ„ï¼š

```
pkdata/
â”œâ”€â”€ patient_id_1/
â”‚   â”œâ”€â”€ patient_id_1_slice_001_ct.png
â”‚   â”œâ”€â”€ patient_id_1_slice_001_pet.png
â”‚   â”œâ”€â”€ patient_id_1_slice_001_mask.png
â”‚   â””â”€â”€ ...
â”œâ”€â”€ patient_id_2/
â””â”€â”€ ...
```

### è®­ç»ƒæ¨¡å‹

#### åŸºç¡€è®­ç»ƒå‘½ä»¤

```bash
python main.py --train --use_gpu \
    --dataset_root ./pkdata/ \
    --dataset_type pclt20k \
    --model_type vmamba \
    --epoch 50 \
    --bs 4 \
    --lr 6e-5 \
    --loss_type tversky_bce \
    --tversky_weight 0.7 \
    --bce_weight 0.3 \
    --tversky_alpha 0.7 \
    --tversky_beta 0.3 \
    --patience 25 \
    --warmup_epochs 5 \
    --weight_decay 0.01 \
    --amp
```

#### ä½¿ç”¨é…ç½®æ–‡ä»¶

```bash
python main.py --train --use_gpu \
    --config logs/20251218_230355/config.json \
    --dataset_root ./pkdata/
```

#### æ¢å¤è®­ç»ƒ

```bash
python main.py --train --use_gpu \
    --dataset_root ./pkdata/ \
    --resume \
    --resume_ckpt logs/20251218_230355/checkpoint_epoch_30.pth
```

### æµ‹è¯•æ¨¡å‹

```bash
python test_model.py \
    --ckpt logs/20251218_230355/best_model.pth \
    --use_gpu \
    --mode eval \
    --dataset_root ./pkdata/ \
    --split test \
    --save_predictions
```

---

## ğŸ“ˆ è®­ç»ƒé…ç½®è¯¦è§£

### æŸå¤±å‡½æ•°

#### Tversky + BCE Loss (æ¨è) â­

```bash
--loss_type tversky_bce \
--tversky_weight 0.7 \
--bce_weight 0.3 \
--tversky_alpha 0.7 \  # FNæƒé‡ (æ¼æ£€æƒ©ç½š)
--tversky_beta 0.3     # FPæƒé‡ (è¯¯æ£€æƒ©ç½š)
```

**Tversky Losså…¬å¼**:
```
Tversky = TP / (TP + Î±*FN + Î²*FP)
Loss = 1 - Tversky
```

**ä¼˜åŠ¿**:
- **æ§åˆ¶æ¼æ£€**: Î±=0.7, Î²=0.3 æ›´å…³æ³¨å‡é˜´æ€§ï¼Œé€‚åˆè‚¿ç˜¤åˆ†å‰²
- **ç¨³å®šè®­ç»ƒ**: BCEæä¾›ç¨³å®šçš„æ¢¯åº¦
- **æœ€ä½³æ€§èƒ½**: åœ¨éªŒè¯é›†ä¸Šè¾¾åˆ°0.775 Dice

#### å…¶ä»–æŸå¤±å‡½æ•°

| æŸå¤±å‡½æ•° | å‘½ä»¤ | é€‚ç”¨åœºæ™¯ |
|---------|------|---------|
| Combined (Dice+CE) | `--loss_type combined` | é€šç”¨åˆ†å‰² |
| Dice | `--loss_type dice` | å°ç›®æ ‡åˆ†å‰² |
| IoU | `--loss_type iou` | ç›´æ¥ä¼˜åŒ–IoU |
| Focal | `--loss_type focal` | éš¾æ ·æœ¬å¤š |

### ä¼˜åŒ–å™¨é…ç½®

```python
# AdamWä¼˜åŒ–å™¨ (ä¸CIPAä¸€è‡´)
optimizer = torch.optim.AdamW(
    param_groups,  # å‚æ•°åˆ†ç»„
    lr=6e-5,
    betas=(0.9, 0.999),
    eps=1e-8,
    weight_decay=0.01
)

# å‚æ•°åˆ†ç»„ç­–ç•¥
# - Linear/Conv: ä½¿ç”¨weight_decay
# - BatchNorm/LayerNorm: weight_decay=0.0
```

### å­¦ä¹ ç‡è°ƒåº¦

```python
# CIPAé£æ ¼: åŸºäºstepæ•°çš„ä½™å¼¦é€€ç«
# - Warm-up: 5 epochs, èµ·å§‹lr = lr * 1e-3
# - Cosine Annealing: æœ€ç»ˆlr = lr * 1e-6
# - æ¯ä¸ªbatchæ›´æ–°ä¸€æ¬¡
```

### è®­ç»ƒæŠ€å·§

1. **EMA (Exponential Moving Average)**: è¡°å‡ç‡0.999ï¼Œæå‡æ¨¡å‹ç¨³å®šæ€§
2. **æ··åˆç²¾åº¦è®­ç»ƒ (AMP)**: åŠ é€Ÿè®­ç»ƒï¼ŒèŠ‚çœæ˜¾å­˜
3. **é˜ˆå€¼æ‰«æ**: éªŒè¯æ—¶è‡ªåŠ¨å¯»æ‰¾æœ€ä½³äºŒå€¼åŒ–é˜ˆå€¼
4. **æ—©åœæœºåˆ¶**: Patience=25ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ

---

## ğŸ“‚ ç›®å½•ç»“æ„

```
CoCoSeg/
â”œâ”€â”€ main.py                    # ä¸»è®­ç»ƒ/æµ‹è¯•è„šæœ¬
â”œâ”€â”€ test_model.py              # æ¨¡å‹è¯„ä¼°è„šæœ¬
â”œâ”€â”€ requirements.txt            # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ requirements-dev.txt        # å¼€å‘/å…¨é‡ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ README.md                  # æœ¬æ–‡æ¡£
â”‚
â”œâ”€â”€ models/                     # æ¨¡å‹ç›¸å…³ä»£ç 
â”‚   â”œâ”€â”€ __init__.py            # æ¨¡å—åˆå§‹åŒ–æ–‡ä»¶
â”‚   â”‚
â”‚   â”œâ”€â”€ vmamba/                # VMambaæ ¸å¿ƒæ¨¡å—ç›®å½•
â”‚   â”‚   â”œâ”€â”€ __init__.py        # VMambaæ¨¡å—åˆå§‹åŒ–
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ builder.py          # EncoderDecoderæ„å»ºå™¨
â”‚   â”‚   â”‚                       # - è´Ÿè´£æ„å»ºå®Œæ•´çš„ç¼–ç å™¨-è§£ç å™¨æ¶æ„
â”‚   â”‚   â”‚                       # - æ ¹æ®é…ç½®é€‰æ‹©backbone (sigma_tiny/sigma_small/sigma_base)
â”‚   â”‚   â”‚                       # - é›†æˆç¼–ç å™¨å’Œè§£ç å™¨
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ dual_vmamba.py      # åŒæ¨¡æ€VMambaç¼–ç å™¨
â”‚   â”‚   â”‚                       # - RGBXTransformer: åŒç‹¬ç«‹ç¼–ç å™¨ä¸»ç±»
â”‚   â”‚   â”‚                       # - AdaptiveFusionModule: è‡ªé€‚åº”èåˆæ¨¡å—
â”‚   â”‚   â”‚                       # - vssm_tiny/small/base: ä¸åŒè§„æ¨¡çš„backbone
â”‚   â”‚   â”‚                       # - å®ç°CRM + DCIM + Adaptive Fusionæµç¨‹
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ vmamba.py           # VMambaæ ¸å¿ƒå®ç°
â”‚   â”‚   â”‚                       # - SS2D: äºŒç»´é€‰æ‹©æ€§æ‰«ææ ¸å¿ƒæ¨¡å—
â”‚   â”‚   â”‚                       # - VSSBlock: VMambaåŸºç¡€block
â”‚   â”‚   â”‚                       # - Backbone_VSSM: VMamba backboneå®ç°
â”‚   â”‚   â”‚                       # - CrossMambaFusionBlock: è·¨æ¨¡æ€èåˆblock
â”‚   â”‚   â”‚                       # - CVSSDecoderBlock: è§£ç å™¨block
â”‚   â”‚   â”‚                       # - åŒ…å«CrossScan, CrossMergeç­‰æ ¸å¿ƒæ“ä½œ
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ MambaDecoder.py     # Mambaè§£ç å™¨
â”‚   â”‚   â”‚                       # - MambaDecoder: ä¸»è§£ç å™¨ç±»
â”‚   â”‚   â”‚                       # - PatchExpand: Patchæ‰©å±•ä¸Šé‡‡æ ·
â”‚   â”‚   â”‚                       # - Mamba_up: ä¸Šé‡‡æ ·å±‚
â”‚   â”‚   â”‚                       # - FinalUpsample_X4: æœ€ç»ˆ4å€ä¸Šé‡‡æ ·
â”‚   â”‚   â”‚                       # - å®ç°è·³è·ƒè¿æ¥å’Œç‰¹å¾èåˆ
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ mamba_net_utils.py  # CRMç­‰å·¥å…·æ¨¡å—
â”‚   â”‚   â”‚                       # - ChannelRectifyModule (CRM): é€šé“æ ¡æ­£æ¨¡å—
â”‚   â”‚   â”‚                       # - ChannelWeights: é€šé“æƒé‡å­¦ä¹ 
â”‚   â”‚   â”‚                       # - SS1D: ä¸€ç»´é€‰æ‹©æ€§æ‰«æï¼ˆç”¨äºCRMï¼‰
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ local_vmamba/       # å±€éƒ¨Mambaå®ç°ï¼ˆç”¨äºDCIMï¼‰
â”‚   â”‚   â”‚   â”œâ”€â”€ region_mamba.py # åŒºåŸŸMambaæ¨¡å—
â”‚   â”‚   â”‚   â”‚                   # - SS2D_Region: åŒºåŸŸé€‰æ‹©æ€§æ‰«æ
â”‚   â”‚   â”‚   â”‚                   # - Region_global_Block: åŒºåŸŸå…¨å±€block
â”‚   â”‚   â”‚   â”‚                   # - ç”¨äºDCIMä¸­çš„åŒºåŸŸäº¤äº’
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ local_scan.py   # å±€éƒ¨æ‰«æå®ç°
â”‚   â”‚   â”‚                       # - local_scan: å±€éƒ¨æ‰«æå‡½æ•°
â”‚   â”‚   â”‚                       # - local_reverse: å±€éƒ¨åå‘æ‰«æ
â”‚   â”‚   â”‚                       # - åŸºäºTritonçš„CUDAå®ç°
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ selective_scan/     # Selective Scan CUDAæ‰©å±•
â”‚   â”‚       â”œâ”€â”€ setup.py        # CUDAæ‰©å±•ç¼–è¯‘è„šæœ¬
â”‚   â”‚       â”œâ”€â”€ csrc/           # CUDAæºç ç›®å½•
â”‚   â”‚       â”‚   â””â”€â”€ selective_scan/
â”‚   â”‚       â”‚       â”œâ”€â”€ selective_scan_core.cu    # æ ¸å¿ƒCUDAå®ç°
â”‚   â”‚       â”‚       â”œâ”€â”€ selective_scan_fwd_kernel.cuh  # å‰å‘kernel
â”‚   â”‚       â”‚       â”œâ”€â”€ selective_scan_bwd_kernel.cuh  # åå‘kernel
â”‚   â”‚       â”‚       â””â”€â”€ ...
â”‚   â”‚       â”‚
â”‚   â”‚       â”œâ”€â”€ selective_scan/ # Pythonæ¥å£
â”‚   â”‚       â”‚   â””â”€â”€ selective_scan_interface.py  # SelectiveScanFnæ¥å£
â”‚   â”‚       â”‚
â”‚   â”‚       â””â”€â”€ build/          # ç¼–è¯‘è¾“å‡ºç›®å½•
â”‚   â”‚
â”‚   â”œâ”€â”€ segmentation_loss.py   # åˆ†å‰²æŸå¤±å‡½æ•°å®ç°
â”‚   â”‚                           # - DiceLoss: DiceæŸå¤±
â”‚   â”‚                           # - TverskyLoss: TverskyæŸå¤±ï¼ˆæ§åˆ¶æ¼æ£€ï¼‰
â”‚   â”‚                           # - CombinedSegLoss: Dice+CEç»„åˆæŸå¤±
â”‚   â”‚                           # - FocalLoss: FocalæŸå¤±
â”‚   â”‚                           # - IoULoss: IoUæŸå¤±
â”‚   â”‚
â”‚   â”œâ”€â”€ model.py               # ä¼ ç»ŸåŸºçº¿æ¨¡å‹ï¼ˆä¿ç•™å¯¹æ¯”ï¼‰
â”‚   â”‚                           # - Vgg19_Encoder: VGG19ç¼–ç å™¨
â”‚   â”‚                           # - UNetEncoder: åŸºç¡€UNetç¼–ç å™¨
â”‚   â”‚                           # - DualIndependentEncoderUNet: åŒç‹¬ç«‹ç¼–ç å™¨UNet
â”‚   â”‚                           # - ä¸»é¡¹ç›®ä½¿ç”¨VMambaï¼Œæ­¤æ–‡ä»¶ä¿ç•™ç”¨äºå‚è€ƒ
â”‚   â”‚
â”‚   â”œâ”€â”€ train_tasks.py         # è®­ç»ƒä»»åŠ¡ç›¸å…³ï¼ˆæ—§ç‰ˆè®­ç»ƒä»£ç ï¼‰
â”‚   â”‚                           # - åŒ…å«æ—§çš„è®­ç»ƒå¾ªç¯å®ç°
â”‚   â”‚                           # - æœ¬é¡¹ç›®ä½¿ç”¨main.pyè¿›è¡Œè®­ç»ƒ
â”‚   â”‚
â”‚   â”œâ”€â”€ measure_model.py       # æ¨¡å‹å‚æ•°é‡/FLOPsæµ‹é‡å·¥å…·
â”‚   â”‚                           # - ä½¿ç”¨torchstatç»Ÿè®¡æ¨¡å‹å‚æ•°å’Œè®¡ç®—é‡
â”‚   â”‚
â”‚   â””â”€â”€ P_loss.py              # VGG19æ„ŸçŸ¥æŸå¤±ï¼ˆå›¾åƒé‡å»ºä»»åŠ¡ç”¨ï¼‰
â”‚                               # - æœ¬é¡¹ç›®ä¸ºåˆ†å‰²ä»»åŠ¡ï¼Œä¸ä½¿ç”¨æ­¤æ–‡ä»¶
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ dataset.py              # PCLT20Kæ•°æ®é›†åŠ è½½å™¨
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ ema.py                 # EMAå®ç°
â”‚   â”œâ”€â”€ early_stopping.py      # æ—©åœæœºåˆ¶
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ logs/                      # è®­ç»ƒæ—¥å¿—
â”‚   â””â”€â”€ 20251218_230355/
â”‚       â”œâ”€â”€ best_model.pth     # æœ€ä½³æ¨¡å‹
â”‚       â”œâ”€â”€ latest.pth         # æœ€æ–°æ¨¡å‹
â”‚       â”œâ”€â”€ checkpoint_epoch_*.pth  # å®šæœŸcheckpoint
â”‚       â”œâ”€â”€ history.json       # è®­ç»ƒå†å²
â”‚       â”œâ”€â”€ config.json        # è®­ç»ƒé…ç½®
â”‚       â””â”€â”€ tensorboard/       # TensorBoardæ—¥å¿—
â”‚
â””â”€â”€ pretrained/
    â””â”€â”€ vmamba/
        â””â”€â”€ vssmtiny_dp01_ckpt_epoch_292.pth  # VMambaé¢„è®­ç»ƒæƒé‡
```

---

## ğŸ“ æ¨¡å‹æ–‡ä»¶è¯¦è§£

### æ ¸å¿ƒæ¶æ„æ–‡ä»¶

#### 1. `models/vmamba/builder.py` - æ¨¡å‹æ„å»ºå™¨

**ä½œç”¨**: æ„å»ºå®Œæ•´çš„ç¼–ç å™¨-è§£ç å™¨æ¶æ„ï¼Œæ˜¯æ¨¡å‹çš„å…¥å£ç‚¹ã€‚

**ä¸»è¦ç±»**:
- `EncoderDecoder`: å®Œæ•´çš„ç¼–ç å™¨-è§£ç å™¨æ¨¡å‹ç±»
  - æ ¹æ®é…ç½®é€‰æ‹©backbone (sigma_tiny / sigma_small / sigma_base)
  - é›†æˆåŒæ¨¡æ€ç¼–ç å™¨ä¸ `MambaDecoder`
  - å½“å‰é»˜è®¤ `deep_supervision=False`ï¼ˆä¸CIPAä¸€è‡´ï¼‰
  - å¤„ç†æ¨¡å‹åˆå§‹åŒ–å’Œæƒé‡åŠ è½½

**ä½¿ç”¨æµç¨‹**:
```python
from models.vmamba.builder import EncoderDecoder
model = EncoderDecoder(cfg=config, criterion=loss_fn)
```

#### 2. `models/vmamba/dual_vmamba.py` - åŒæ¨¡æ€ç¼–ç å™¨

**ä½œç”¨**: å®ç°CT-PETåŒæ¨¡æ€ç‰¹å¾æå–å’Œå¤šå±‚çº§èåˆã€‚

**ä¸»è¦ç±»**:
- `RGBXTransformer`: åŒæ¨¡æ€ç¼–ç å™¨ä¸»ç±»
  - åŒ…å«ä¸¤ä¸ªç‹¬ç«‹çš„VMambaç¼–ç å™¨ï¼ˆCTå’ŒPETï¼‰
  - å®ç°4ä¸ªå±‚çº§çš„ç‰¹å¾èåˆï¼ˆCRM + DCIM + Adaptive Fusionï¼‰
  - è¾“å‡ºèåˆåçš„å¤šå°ºåº¦ç‰¹å¾
  
- `AdaptiveFusionModule`: è‡ªé€‚åº”èåˆæ¨¡å—
  - å­¦ä¹ CTå’ŒPETçš„æœ€ä¼˜èåˆæƒé‡
  - åŸºäºå…¨å±€å¹³å‡æ± åŒ–å’Œå…¨è¿æ¥å±‚

- `vssm_tiny / vssm_small / vssm_base`: ä¸åŒè§„æ¨¡çš„backboneé…ç½®

**æ•°æ®æµ**:
```
CTè¾“å…¥ â†’ CT_VMamba â†’ [96,192,384,768]ç‰¹å¾
PETè¾“å…¥ â†’ PET_VMamba â†’ [96,192,384,768]ç‰¹å¾
         â†“
    4å±‚èåˆ (CRM â†’ DCIM â†’ Adaptive Fusion)
         â†“
    èåˆç‰¹å¾ [96,192,384,768]
```

#### 3. `models/vmamba/vmamba.py` - VMambaæ ¸å¿ƒå®ç°

**ä½œç”¨**: VMambaæ¶æ„çš„æ ¸å¿ƒæ¨¡å—ï¼ŒåŒ…å«æ‰€æœ‰åŸºç¡€ç»„ä»¶ã€‚

**ä¸»è¦ç±»å’Œå‡½æ•°**:
- `SS2D`: äºŒç»´é€‰æ‹©æ€§æ‰«ææ¨¡å—ï¼ˆVMambaçš„æ ¸å¿ƒï¼‰
  - å®ç°CrossScan â†’ SelectiveScan â†’ CrossMergeæµç¨‹
  - çº¿æ€§å¤æ‚åº¦O(N)çš„çŠ¶æ€ç©ºé—´æ¨¡å‹
  
- `VSSBlock`: VMambaåŸºç¡€block
  - åŒ…å«SS2D + MLP + æ®‹å·®è¿æ¥
  - ç±»ä¼¼Transformerçš„blockç»“æ„

- `Backbone_VSSM`: VMamba backboneå®ç°
  - 4ä¸ªstageçš„å±‚æ¬¡åŒ–ç‰¹å¾æå–
  - æ”¯æŒä¸åŒè§„æ¨¡é…ç½®ï¼ˆtiny/small/baseï¼‰

- `CrossMambaFusionBlock`: è·¨æ¨¡æ€èåˆblock
  - ç”¨äºç¼–ç å™¨ä¸­çš„è·¨æ¨¡æ€äº¤äº’

- `CVSSDecoderBlock`: è§£ç å™¨block
  - ç”¨äºMambaDecoderä¸­çš„ç‰¹å¾ä¸Šé‡‡æ ·

**å…³é”®æ“ä½œ**:
- `CrossScan`: å°†2Dç‰¹å¾è½¬æ¢ä¸º4ä¸ªæ–¹å‘çš„1Dåºåˆ—
- `SelectiveScan`: çŠ¶æ€ç©ºé—´æ¨¡å‹çš„å‰å‘ä¼ æ’­
- `CrossMerge`: å°†4ä¸ªæ–¹å‘çš„ç»“æœåˆå¹¶å›2D

#### 4. `models/vmamba/MambaDecoder.py` - Mambaè§£ç å™¨

**ä½œç”¨**: åŸºäºVMambaçš„ä¸Šé‡‡æ ·è§£ç å™¨ï¼Œé€æ­¥æ¢å¤åˆ†è¾¨ç‡ã€‚

**ä¸»è¦ç±»**:
- `MambaDecoder`: ä¸»è§£ç å™¨ç±»
  - 4ä¸ªä¸Šé‡‡æ ·å±‚ï¼Œé€æ­¥ä»16Ã—16æ¢å¤åˆ°128Ã—128
  - ä¸ç¼–ç å™¨ç‰¹å¾è¿›è¡Œè·³è·ƒè¿æ¥
  - æœ€ç»ˆ4å€ä¸Šé‡‡æ ·åˆ°512Ã—512

- `PatchExpand`: Patchæ‰©å±•ä¸Šé‡‡æ ·
  - é€šè¿‡çº¿æ€§å˜æ¢å’Œreshapeå®ç°2å€ä¸Šé‡‡æ ·

- `Mamba_up`: ä¸Šé‡‡æ ·å±‚
  - åŒ…å«CVSSDecoderBlockå’Œå¯é€‰çš„PatchExpand

- `FinalUpsample_X4`: æœ€ç»ˆ4å€ä¸Šé‡‡æ ·
  - ä½¿ç”¨åŒçº¿æ€§æ’å€¼å¿«é€Ÿä¸Šé‡‡æ ·åˆ°åŸå§‹åˆ†è¾¨ç‡

**è§£ç æµç¨‹**:
```
èåˆç‰¹å¾[768,16Ã—16] â†’ PatchExpand â†’ [384,32Ã—32]
    â†“ + Skip(384)
Mamba_up â†’ [192,64Ã—64]
    â†“ + Skip(192)
Mamba_up â†’ [96,128Ã—128]
    â†“ + Skip(96)
Mamba_up â†’ [96,128Ã—128]
    â†“
FinalUpsample_X4 â†’ [1,512Ã—512]
```

#### 5. `models/vmamba/mamba_net_utils.py` - èåˆå·¥å…·æ¨¡å—

**ä½œç”¨**: å®ç°CRM (Channel Rectify Module)ç­‰èåˆç›¸å…³å·¥å…·ã€‚

**ä¸»è¦ç±»**:
- `ChannelRectifyModule (CRM)`: é€šé“æ ¡æ­£æ¨¡å—
  - å­¦ä¹ CTå’ŒPETç‰¹å¾çš„é€šé“é‡è¦æ€§æƒé‡
  - å¯¹é‡è¦é€šé“è¿›è¡ŒåŠ æƒå¢å¼º
  
- `ChannelWeights`: é€šé“æƒé‡å­¦ä¹ 
  - ä½¿ç”¨SS1Då¤„ç†é€šé“åºåˆ—
  - è¾“å‡ºæ¯ä¸ªé€šé“çš„é‡è¦æ€§æƒé‡

- `SS1D`: ä¸€ç»´é€‰æ‹©æ€§æ‰«æ
  - ç”¨äºCRMä¸­çš„é€šé“æƒé‡å­¦ä¹ 
  - è½»é‡çº§çš„çŠ¶æ€ç©ºé—´æ¨¡å‹

**CRMå·¥ä½œæµç¨‹**:
```
CTç‰¹å¾ + PETç‰¹å¾ â†’ æ‹¼æ¥ â†’ SS1Då¤„ç† â†’ é€šé“æƒé‡
    â†“
åŠ æƒå¢å¼º â†’ è¾“å‡ºæ ¡æ­£åçš„CTå’ŒPETç‰¹å¾
```

#### 6. `models/vmamba/local_vmamba/` - å±€éƒ¨Mamba

**ä½œç”¨**: å®ç°DCIMä¸­çš„åŒºåŸŸçº§äº¤äº’ã€‚

**ä¸»è¦æ–‡ä»¶**:
- `region_mamba.py`: åŒºåŸŸMambaå®ç°
  - `SS2D_Region`: åŒºåŸŸé€‰æ‹©æ€§æ‰«æ
  - `Region_global_Block`: åŒºåŸŸå…¨å±€äº¤äº’block
  - å°†ç‰¹å¾å›¾åˆ’åˆ†ä¸ºå¤šä¸ªåŒºåŸŸï¼Œæ¯ä¸ªåŒºåŸŸç‹¬ç«‹å¤„ç†

- `local_scan.py`: å±€éƒ¨æ‰«æå®ç°
  - `local_scan`: å±€éƒ¨çª—å£æ‰«æ
  - åŸºäºTritonçš„CUDAåŠ é€Ÿå®ç°

**DCIMå·¥ä½œæµç¨‹**:
```
CTç‰¹å¾ + PETç‰¹å¾ â†’ Region Patch (åˆ†å—)
    â†“
æ¯ä¸ªåŒºåŸŸç‹¬ç«‹å¤„ç† â†’ Channel Attention Mamba
    â†“
è·¨æ¨¡æ€åŒºåŸŸäº¤äº’ â†’ è¾“å‡ºå¢å¼ºç‰¹å¾
```

#### 7. `models/vmamba/selective_scan/` - CUDAæ‰©å±•

**ä½œç”¨**: Selective Scançš„CUDAåŠ é€Ÿå®ç°ï¼Œæå‡è®¡ç®—æ•ˆç‡ã€‚

**å…³é”®æ–‡ä»¶**:
- `setup.py`: ç¼–è¯‘è„šæœ¬ï¼Œç”¨äºæ„å»ºCUDAæ‰©å±•
- `csrc/selective_scan/`: CUDAæºç 
  - `selective_scan_core.cu`: æ ¸å¿ƒCUDAå®ç°
  - `selective_scan_fwd_kernel.cuh`: å‰å‘ä¼ æ’­kernel
  - `selective_scan_bwd_kernel.cuh`: åå‘ä¼ æ’­kernel
- `selective_scan/selective_scan_interface.py`: Pythonæ¥å£

**ç¼–è¯‘æ–¹æ³•**:
```bash
cd models/vmamba/selective_scan
python setup.py build_ext --inplace
```

### æŸå¤±å‡½æ•°æ–‡ä»¶

#### `models/segmentation_loss.py` - åˆ†å‰²æŸå¤±å‡½æ•°

**ä½œç”¨**: å®ç°å„ç§åˆ†å‰²ä»»åŠ¡å¸¸ç”¨çš„æŸå¤±å‡½æ•°ã€‚

**ä¸»è¦ç±»**:
- `DiceLoss`: DiceæŸå¤±
  - é€‚ç”¨äºäºŒå€¼åˆ†å‰²ï¼Œå¯¹å°ç›®æ ‡å‹å¥½
  - æŒ‰æ ·æœ¬è®¡ç®—ï¼Œä¸CIPAä¿æŒä¸€è‡´

- `TverskyLoss`: TverskyæŸå¤± â­
  - å¯æ§åˆ¶å‡é˜´æ€§(FN)å’Œå‡é˜³æ€§(FP)çš„æƒé‡
  - é€‚åˆè‚¿ç˜¤åˆ†å‰²ï¼ˆæ›´å…³æ³¨æ¼æ£€ï¼‰
  - å‚æ•°: alpha (FNæƒé‡), beta (FPæƒé‡)

- `CombinedSegLoss`: ç»„åˆæŸå¤±
  - Dice + CrossEntropyçš„ç»„åˆ
  - å¹³è¡¡é‡å åº¦å’Œåˆ†ç±»å‡†ç¡®æ€§

- `FocalLoss`: FocalæŸå¤±
  - å…³æ³¨éš¾æ ·æœ¬ï¼Œé™ä½æ˜“æ ·æœ¬æƒé‡

- `IoULoss`: IoUæŸå¤±
  - ç›´æ¥ä¼˜åŒ–IoUæŒ‡æ ‡

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from models.segmentation_loss import TverskyLoss
loss_fn = TverskyLoss(alpha=0.7, beta=0.3, smooth=1e-6)
loss = loss_fn(pred, target)
```

### è¾…åŠ©æ–‡ä»¶

#### `models/model.py` - ä¼ ç»ŸåŸºçº¿æ¨¡å‹

**ä½œç”¨**: åŒ…å«VGG/UNetç›¸å…³åŸºçº¿æ¨¡å‹ï¼Œä¿ç•™ç”¨äºå¯¹æ¯”å®éªŒã€‚

**ä¸»è¦ç±»**:
- `Vgg19_Encoder`: VGG19ç¼–ç å™¨ï¼ˆç°åº¦è¾“å…¥ï¼‰
  - æå–ä¸‰å±‚ç‰¹å¾ï¼ˆ64/128/256 channelsï¼‰
- `UNetEncoder`: åŸºç¡€UNetç¼–ç å™¨
- `DualIndependentEncoderUNet`: åŒç‹¬ç«‹ç¼–ç å™¨UNetï¼ˆCT/PETå„è‡ªç¼–ç å™¨ï¼‰

**æ³¨æ„**: å½“å‰ä¸»æ¨¡å‹ä¸ºVMambaæ¶æ„ï¼Œæ­¤æ–‡ä»¶ä¿ç•™ç”¨äºå‚è€ƒå’Œå¯¹æ¯”ã€‚

#### `models/train_tasks.py` - æ—§ç‰ˆè®­ç»ƒä»£ç 

**ä½œç”¨**: æ—§çš„è®­ç»ƒå¾ªç¯å®ç°ï¼Œæœ¬é¡¹ç›®å·²è¿ç§»åˆ°`main.py`ã€‚

**æ³¨æ„**: å½“å‰è®­ç»ƒä½¿ç”¨`main.py`ï¼Œæ­¤æ–‡ä»¶ä¿ç•™ç”¨äºå‚è€ƒã€‚

#### `models/measure_model.py` - æ¨¡å‹æµ‹é‡å·¥å…·

**ä½œç”¨**: ç»Ÿè®¡æ¨¡å‹çš„å‚æ•°é‡å’ŒFLOPsã€‚

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from models.measure_model import measure_model
params, flops = measure_model(model, input_size=(1, 3, 512, 512))
```

#### `models/P_loss.py` - æ„ŸçŸ¥æŸå¤±

**ä½œç”¨**: VGG19æ„ŸçŸ¥æŸå¤±ï¼Œç”¨äºå›¾åƒé‡å»ºä»»åŠ¡ã€‚

**æ³¨æ„**: æœ¬é¡¹ç›®ä¸ºåˆ†å‰²ä»»åŠ¡ï¼Œä¸ä½¿ç”¨æ­¤æ–‡ä»¶ã€‚

---

## ğŸ”¬ æ¨¡å‹åˆ›æ–°ç‚¹

### 1. VMambaæ¶æ„çš„ä¼˜åŠ¿

- **çº¿æ€§å¤æ‚åº¦**: O(N) vs Transformerçš„O(NÂ²)
- **é•¿è·ç¦»ä¾èµ–**: SSMå¤©ç„¶é€‚åˆå»ºæ¨¡é•¿åºåˆ—
- **é«˜æ•ˆè®¡ç®—**: é€‚åˆé«˜åˆ†è¾¨ç‡åŒ»ç–—å›¾åƒ(512Ã—512)

### 2. åŒç‹¬ç«‹ç¼–ç å™¨è®¾è®¡

- **æ¨¡æ€ç‰¹å¼‚æ€§**: CTå’ŒPETç‹¬ç«‹å­¦ä¹ å„è‡ªç‰¹å¾
- **é¢„è®­ç»ƒåˆ©ç”¨**: å•é€šé“â†’3é€šé“ï¼Œå……åˆ†åˆ©ç”¨ImageNeté¢„è®­ç»ƒ
- **ç‰¹å¾äº’è¡¥**: èåˆé˜¶æ®µå®ç°äº’è¡¥å¢å¼º

### 3. å¤šå±‚çº§èåˆæœºåˆ¶

- **CRM**: é€šé“çº§åˆ«çš„è·¨æ¨¡æ€å¯¹é½
- **DCIM**: åŒºåŸŸçº§åˆ«çš„ç»†ç²’åº¦äº¤äº’
- **Adaptive Fusion**: è‡ªé€‚åº”å­¦ä¹ æœ€ä¼˜èåˆæƒé‡

### 4. å…ˆè¿›è®­ç»ƒç­–ç•¥

- **EMA**: æå‡æ¨¡å‹ç¨³å®šæ€§
- **é˜ˆå€¼æ‰«æ**: è‡ªåŠ¨å¯»æ‰¾æœ€ä½³é˜ˆå€¼
- **æ··åˆç²¾åº¦**: åŠ é€Ÿè®­ç»ƒï¼ŒèŠ‚çœæ˜¾å­˜

---

## ğŸ“Š è¯„ä¼°æŒ‡æ ‡

æ¨¡å‹æ”¯æŒä»¥ä¸‹è¯„ä¼°æŒ‡æ ‡ï¼š

- **Diceç³»æ•°**: è¡¡é‡é‡å åº¦ï¼ŒèŒƒå›´[0,1]ï¼Œè¶Šå¤§è¶Šå¥½
- **IoU (Intersection over Union)**: äº¤å¹¶æ¯”ï¼ŒèŒƒå›´[0,1]
- **F1åˆ†æ•°**: ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡
- **HD95 (95% Hausdorffè·ç¦»)**: è¾¹ç•Œç²¾åº¦ï¼Œå•ä½mmï¼Œè¶Šå°è¶Šå¥½
- **å‡†ç¡®ç‡**: æ­£ç¡®åƒç´ æ¯”ä¾‹

---

## ğŸ”§ è¶…å‚æ•°è°ƒä¼˜å»ºè®®

### å­¦ä¹ ç‡

- **åˆå§‹å­¦ä¹ ç‡**: 6e-5 (VMamba Tinyæ¨è)
- **Warm-up**: 5 epochs
- **è°ƒåº¦ç­–ç•¥**: ä½™å¼¦é€€ç«

### æ‰¹æ¬¡å¤§å°

æ ¹æ®GPUæ˜¾å­˜é€‰æ‹©ï¼š
- **4GB**: bs=2
- **8GB**: bs=4 (æ¨è)
- **16GB+**: bs=8

### æŸå¤±å‡½æ•°æƒé‡

- **Tverskyæƒé‡**: 0.7 (æ¨èï¼Œæ›´å…³æ³¨æ¼æ£€)
- **BCEæƒé‡**: 0.3
- **Alpha/Beta**: 0.7/0.3 (è‚¿ç˜¤åˆ†å‰²æ¨è)

### æ•°æ®å¢å¼º

- **éšæœºè£å‰ª**: 512Ã—512
- **éšæœºç¿»è½¬**: æ°´å¹³/å‚ç›´
- **éšæœºæ—‹è½¬**: Â±15åº¦
- **äº®åº¦/å¯¹æ¯”åº¦è°ƒæ•´**: Â±20%

---

## ğŸ“¦ ä¾èµ–é¡¹

### æ ¸å¿ƒä¾èµ–

- **PyTorch**: >=2.1.0 (æ¨èCUDA 12.1+)
- **torchvision**: >=0.16.0
- **numpy**: >=1.24.0,<2.0.0
- **opencv-python**: >=4.8.0
- **pillow**: >=10.0.0

### VMambaç›¸å…³

- **einops**: >=0.7.0 (å¼ é‡æ“ä½œ)
- **timm**: >=0.9.0 (æ¨¡å‹å·¥å…·)
- **selective_scan**: CUDAæ‰©å±• (éœ€ç¼–è¯‘)

### è®­ç»ƒå·¥å…·

- **tensorboard**: >=2.14.0
- **tqdm**: >=4.66.0
- **albumentations**: >=1.3.0 (æ•°æ®å¢å¼º)
- **scipy**: >=1.11.0 (HD95è®¡ç®—)

å®Œæ•´ä¾èµ–åˆ—è¡¨è¯·æŸ¥çœ‹ `requirements.txt`ã€‚

---

## ğŸ“ æœ€ä½³å®è·µ

1. âœ… **ä½¿ç”¨Tversky+BCEæŸå¤±**: é€‚åˆè‚¿ç˜¤åˆ†å‰²ï¼Œæ§åˆ¶æ¼æ£€
2. âœ… **å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ**: åŠ é€Ÿè®­ç»ƒï¼ŒèŠ‚çœæ˜¾å­˜
3. âœ… **ä½¿ç”¨EMA**: æå‡æ¨¡å‹ç¨³å®šæ€§
4. âœ… **é˜ˆå€¼æ‰«æ**: éªŒè¯æ—¶è‡ªåŠ¨å¯»æ‰¾æœ€ä½³é˜ˆå€¼
5. âœ… **ç›‘æ§HD95**: è¾¹ç•Œç²¾åº¦çš„é‡è¦æŒ‡æ ‡
6. âœ… **æ—©åœæœºåˆ¶**: é˜²æ­¢è¿‡æ‹Ÿåˆ
7. âœ… **å›ºå®šéšæœºç§å­**: ç¡®ä¿å¯å¤ç°

---

## ğŸ¤ è´¡çŒ®

æœ¬é¡¹ç›®åŸºäºVMambaå’ŒCIPAæ¶æ„ä¿®æ”¹ï¼Œæ¬¢è¿æå‡ºæ”¹è¿›å»ºè®®ã€‚

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªMITè®¸å¯è¯ã€‚

## ğŸ™ è‡´è°¢

- **VMamba**: Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model
- **CIPA**: åŒæ¨¡æ€åŒ»ç–—å›¾åƒåˆ†å‰²æ¡†æ¶
- **Mamba**: Efficient Language Modeling with State Space Models

## ğŸ“§ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·æäº¤Issueã€‚

---

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. Liu, Y., et al. "Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model." arXiv preprint (2024).
2. Gu, A., & Dao, T. "Mamba: Linear-Time Sequence Modeling with Selective State Spaces." arXiv preprint (2023).
3. CIPA: åŒæ¨¡æ€åŒ»ç–—å›¾åƒåˆ†å‰²æ¡†æ¶ (å†…éƒ¨é¡¹ç›®)

---

**æœ€åæ›´æ–°**: 2024-12-18  
**æ¨¡å‹ç‰ˆæœ¬**: VMamba-Tiny + MambaDecoder  
**æœ€ä½³æ€§èƒ½**: Dice=0.7755 @ é˜ˆå€¼=0.35
